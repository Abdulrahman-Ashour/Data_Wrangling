{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import tweepy \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.sort_values('timestamp')\n",
    "twitter_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('image-predictions.tsv', mode ='wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "#Read TSV file\n",
    "image_prediction = pd.read_csv('image-predictions.tsv', sep='\\t' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler('5Uur0mo4ol2kB8yhtZ1VxXS0u', 'h8E7fSpXWiMoBel7G1ZOAeu4Mgru0v0MtxH5ehYE1RKM89SiBH')\n",
    "auth.set_access_token('303562412-ct9aNnU0FQR0UKJVn1i1W3Y8omqSewiQWUcRaygB', 'D3qslrbdOU5fqTOp951kOIuZbkeTPBodnjNYoEGFR63Ft')\n",
    "api = tweepy.API(auth, \n",
    "                 parser = tweepy.parsers.JSONParser(), \n",
    "                 wait_on_rate_limit = True, \n",
    "                 wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tweets = []\n",
    "# Tweets that can't be found are saved in the list below:\n",
    "cant_find_tweets_for_those_ids = []\n",
    "for tweet_id in twitter_archive['tweet_id']:   \n",
    "    try:\n",
    "        list_of_tweets.append(api.get_status(tweet_id))\n",
    "    except Exception as e:\n",
    "        cant_find_tweets_for_those_ids.append(tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The list of tweets\" ,len(list_of_tweets))\n",
    "print(\"The list of tweets no found\" , len(cant_find_tweets_for_those_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list_of_dicts = []\n",
    "for each_json_tweet in list_of_tweets:\n",
    "    my_list_of_dicts.append(each_json_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_json.txt', 'w') as file:\n",
    "        file.write(json.dumps(my_list_of_dicts, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_demo_list = []\n",
    "with open('tweet_json.txt', encoding='utf-8') as json_file:  \n",
    "    all_data = json.load(json_file)\n",
    "    for each_dictionary in all_data:\n",
    "        tweet_id = each_dictionary['id']\n",
    "        whole_tweet = each_dictionary['text']\n",
    "        only_url = whole_tweet[whole_tweet.find('https'):]\n",
    "        favorite_count = each_dictionary['favorite_count']\n",
    "        retweet_count = each_dictionary['retweet_count']\n",
    "        followers_count = each_dictionary['user']['followers_count']\n",
    "        friends_count = each_dictionary['user']['friends_count']\n",
    "        whole_source = each_dictionary['source']\n",
    "        only_device = whole_source[whole_source.find('rel=\"nofollow\">') + 15:-4]\n",
    "        source = only_device\n",
    "        retweeted_status = each_dictionary['retweeted_status'] = each_dictionary.get('retweeted_status', 'Original tweet')\n",
    "        if retweeted_status == 'Original tweet':\n",
    "            url = only_url\n",
    "        else:\n",
    "            retweeted_status = 'This is a retweet'\n",
    "            url = 'This is a retweet'\n",
    "\n",
    "        my_demo_list.append({'tweet_id': str(tweet_id),\n",
    "                             'favorite_count': int(favorite_count),\n",
    "                             'retweet_count': int(retweet_count),\n",
    "                             'followers_count': int(followers_count),\n",
    "                             'friends_count': int(friends_count),\n",
    "                             'url': url,\n",
    "                             'source': source,\n",
    "                             'retweeted_status': retweeted_status,\n",
    "                            })\n",
    "        tweet_json = pd.DataFrame(my_demo_list, columns = ['tweet_id', 'favorite_count','retweet_count', \n",
    "                                                           'followers_count', 'friends_count','source', \n",
    "                                                           'retweeted_status', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(twitter_archive['tweet_id'].duplicated())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.rating_numerator.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twitter_archive.loc[twitter_archive.rating_numerator == 204, 'text']) \n",
    "print(twitter_archive.loc[twitter_archive.rating_numerator == 143, 'text']) \n",
    "print(twitter_archive.loc[twitter_archive.rating_numerator == 666, 'text']) \n",
    "print(twitter_archive.loc[twitter_archive.rating_numerator == 1176, 'text'])\n",
    "print(twitter_archive.loc[twitter_archive.rating_numerator == 144, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twitter_archive['text'][1120]) #17 dogs\n",
    "print(twitter_archive['text'][1634]) #13 dogs\n",
    "print(twitter_archive['text'][313]) #just a tweet to explain actual ratings, this will be ignored when cleaning data\n",
    "print(twitter_archive['text'][189]) #no picture, this will be ignored when cleaning data\n",
    "print(twitter_archive['text'][1779]) #12 dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.rating_denominator.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twitter_archive.loc[twitter_archive.rating_denominator == 11, 'text']) \n",
    "print(twitter_archive.loc[twitter_archive.rating_denominator == 2, 'text']) \n",
    "print(twitter_archive.loc[twitter_archive.rating_denominator == 16, 'text']) \n",
    "print(twitter_archive.loc[twitter_archive.rating_denominator == 15, 'text'])\n",
    "print(twitter_archive.loc[twitter_archive.rating_denominator == 7, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twitter_archive['text'][784]) #retweet - it will be deleted when delete all retweets\n",
    "print(twitter_archive['text'][1068]) #actual rating 14/10 need to change manually\n",
    "print(twitter_archive['text'][1662]) #actual rating 10/10 need to change manually\n",
    "print(twitter_archive['text'][2335]) #actual rating 9/10 need to change manually\n",
    "print(twitter_archive['text'][1663]) # tweet to explain rating\n",
    "print(twitter_archive['text'][342]) #no rating - delete\n",
    "print(twitter_archive['text'][516]) #no rating - delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive['tweet_id'] == 681340665377193000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('max_colwidth', 200):\n",
    "    display(twitter_archive[twitter_archive['text'].str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]\n",
    "            [['tweet_id', 'text', 'rating_numerator', 'rating_denominator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(image_prediction.jpg_url.duplicated())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(g for _, g in image_prediction.groupby(\"jpg_url\") if len(g) > 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_prediction.p1_dog.value_counts())\n",
    "print(image_prediction.p2_dog.value_counts())\n",
    "print(image_prediction.p3_dog.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.img_num.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.retweeted_status.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.source.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
